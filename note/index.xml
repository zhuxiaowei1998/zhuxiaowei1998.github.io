<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Notes on Xiaowei</title>
    <link>https://zhuxiaowei1998.github.io/note/</link>
    <description>Recent content in Notes on Xiaowei</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://zhuxiaowei1998.github.io/note/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>白灼秋葵</title>
      <link>https://zhuxiaowei1998.github.io/note/2022/01/04/okra/</link>
      <pubDate>Tue, 04 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2022/01/04/okra/</guid>
      <description>refer to 下厨房
 用料：秋葵、蒜、生抽、蚝油、盐、糖
做法：
 清洗秋葵，去头 放盐焯水；切蒜末；调料碗里放生抽、蚝油、糖 盛出秋葵放盘里 另起一锅，热锅热油，放蒜末炒香，倒入调料 浇在秋葵上  Tips:
秋葵不宜放置时间过长，买完后尽早食用</description>
    </item>
    
    <item>
      <title>红烧肉</title>
      <link>https://zhuxiaowei1998.github.io/note/2022/01/04/okra/</link>
      <pubDate>Tue, 04 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2022/01/04/okra/</guid>
      <description>refer to 下厨房
 用料：猪肉、姜、生抽、老抽、料酒、冰糖、八角
做法：
 洗猪肉，厨房用纸吸干表面 热锅，少油，放五花肉，小火慢煎；筷子翻面 放冰糖，姜，八角，料酒，生抽，老抽 加开水漫过表面，大火烧开，小火慢炖 大火收汁  Tips： 猪肉最好用五花肉</description>
    </item>
    
    <item>
      <title>Statistical inference 9</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/31/statistical-inference-9/</link>
      <pubDate>Fri, 31 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/31/statistical-inference-9/</guid>
      <description>Inverse Gaussian Distribution Definition Properties Likelihood, MLE Full exponential family MVUE $IG(\mu, \psi)$, test on $\psi$ $IG(\mu, \psi)$, test on $\mu$ </description>
    </item>
    
    <item>
      <title>日记</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/30/diary/</link>
      <pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/30/diary/</guid>
      <description>专业课  FSI 最后的video看完，过了一遍知识点 过了FSI两年的往年卷  Leetcode  最长公共子序列 丢棋子问题  随记 今天在Leetcode上花了过多的时间（两道题做了近三小时），还没有完全做出来，看答案也没有完全消化吸收。动态规划的题，前期还是不要死磕，毕竟有的题目确实灵活，比较tricky，也不是说花时间就能看出来的，不如老老实实把答案看懂，要点吸收。
刷Leetcode，好的策略是：先自己想一会儿（10分钟），如果有思路，觉得自己应该能做出来，那么就继续想一会儿（10分钟）；如果明显没有思路的，那么就不要再想下去了，直接看题解，消化吸收吧，毕竟消化吸收也是要花不少时间的（20分钟左右）。
比较理想的情况是一道题目花半小时左右。
一个启示是：要清楚自己的能力边界，量力而行，做努努力能获得的事情。不要钻牛角尖。</description>
    </item>
    
    <item>
      <title>Probability</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/29/probability/</link>
      <pubDate>Wed, 29 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/29/probability/</guid>
      <description>The Elements of Probability Theory Algebra and σ-algebra Borel σ-algebra Measure Probability measure Properties of the probability measure Monotone class theorem Caratheodory extension theorem Random Variables and Vectors Random variables Definition Proposition Random vectors Distribution function of a random variable Definition Proposition Distribution function of a random vector Definition Proposition Independence of random variables Independence of random vectors Integration and Expectation Lebesgue-Stieltjes integration Definition Proposition Fatou’s lemma Monotone convergence theorem Dominated convergence theorem Bounded convergence theorem Important inequalities Markov’s inequality Chebychev’s inequality Jensen’s inequality Hölder’s inequality Schwarz’s inequality Minkowski’s inequality Iterated integrals Tonelli’s theorem Fubini’s theorem) Densities Modes of Convergence Almost sure convergence Convergence in probability Convergence in $L^p$ Convergence in distribution Connection between modes of convergence Slutsky’s theorem Convergence of random vectors Multivariate Mann-Wald mapping theorem) Laws of Large Numbers Weak law of large numbers Strong law of large numbers Glivenko-Cantelli theorem) Central Limit Theorems Standard central limit theorem Lindeberg condition Lindeberg’s CLT Uniform asymptotic negligibility (UAN) condition Feller’s theorem Lindeberg-Feller theorem Lyapounov condition Characteristic functions Definition Proposition Cramer-Wold device Delta method Conditional Probability and Expectation Conditional expectation Definition Proposition Markov Chain </description>
    </item>
    
    <item>
      <title>《论语摘录》整理</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/29/analects/</link>
      <pubDate>Wed, 29 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/29/analects/</guid>
      <description>做人 学而时习之，不亦说乎？有朋自远方来，不亦乐乎？人不知而不愠，不亦君子乎？
弟子入则孝，出则悌，谨而信，泛爱众，而亲仁。行有余力，则以学文。
事父母，能竭其力；事君，能致其身；与朋友交，言而有信。
吾十有五而志于学，三十而立，四十而不惑，五十而知天命，六十而耳顺，七十而从心所欲，不逾矩。
饭疏食饮水，曲肱而枕之，乐亦在其中矣。不义而富且贵，于我如浮云。
发愤忘食，乐以忘忧，不知老之将至云尔。
士不可以不弘毅，任重而道远。仁以为己任，不亦重乎？死而后已，不亦远乎？
如有周公之才之美，使骄且吝，其馀不足观也已。
三年学，不至于谷，不易得也。
笃信好学，守死善道。危邦不入，乱邦不居。天下有道则见，无道则隐。邦有道，贫且贱焉，耻也。邦无道，富且贵焉，耻也。
不在其位，不谋其政。
子绝四：毋意，毋必，毋固，毋我。
三军可夺帅也，匹夫不可夺志也。
知者不惑，仁者不忧，勇者不惧。
过犹不及。
在邦无怨，在家无怨。
其身正，不令而行；其身不正，虽令不从。
苟有用我者，期月而已可也，三年有成。
无欲速，无见小利。欲速，则不达；见小利，则大事不成。
行己有耻，使于四方，不辱君命，可谓士矣。
德不孤，必有邻。
目标 老者安之，朋友信之，少者怀之。
内省之功 吾日三省吾身：为人谋而不忠乎？与朋友交而不信乎？传不习乎？
见贤思齐焉，见不贤而内自省也。
季文子三思而后行。子闻之，曰：“再，斯可矣。”
君子之道 君子务本，本立而道生。
君子不重，则不威；学则不固。主忠信，无友不如已者。
君子食无求饱，居无求安，敏于事而慎于言，就有道而正焉，可谓好学也已。
君子不器。
富与贵，是人之所欲也。不以其道得之，不处也。贫与贱，是人之所恶也。不以其道得之，不去也。君子去仁，恶乎成名？君子无终食之间违仁，造次必于是，颠沛必于是。
君子之于天下也，无适也，无莫也，义之与比。
君子喻于义，小人喻于利。
质胜文则野，文胜质则史。文质彬彬，然后君子。
贤哉回也，一箪食，一瓢饮，在陋巷，人不堪其忧，回也不改其乐。贤哉回也。
力不足者，中道而废。今女画。
已欲立而立人，已欲达而达人。
德之不修，学之不讲，闻义不能徙，不善不能改，是吾忧也。
志于道，据于德，依于仁，游于艺。
用之则行，舍之则藏。
富而可求也，虽执鞭之士，吾亦为之。如不可求，从吾所好。
躬行君子，则吾未之有得。
可以托六尺之孤，可以寄百里之命，临大节而不可夺也。君子人与？君子人也
君子居之，何陋之有？
君子不忧不惧。内省不疚，夫何忧何惧。
君子成人之美，不成人之恶。小人反是。
君子坦荡荡，小人长戚戚。
君子和而不同，小人同而不和。
君子泰而不骄，小人骄而不泰。
不如乡人之善者好之，其不善者恶之。
过错 吾未见能见其过而内自讼者也。
过则勿惮改。
不迁怒，不贰过。
君子之过也，如日月之食焉；过也，人皆见之；更也，人皆仰之。
仁 仁者先难而后获，可谓仁矣。
知者乐水，仁者乐山。知者动，仁者静。知者乐，仁者寿。
求仁而得仁，又何怨？
我欲仁，斯仁至矣。
刚、毅、木、讷近仁。
孝 今之孝者，是谓能养。至于犬马，皆能有养。不敬，何以别乎？
父母之年，不可不知也。一则以喜，一则以惧。
父为子隐，子为父隐。直在其中矣。
忠 君使臣以礼，臣事君以忠。</description>
    </item>
    
    <item>
      <title>日记</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/29/diary/</link>
      <pubDate>Wed, 29 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/29/diary/</guid>
      <description>专业课  FSI slides 还剩Inverse Gaussian PfS 过了一遍知识点  读书  《财富自由之路》关于资本 《论语》初步整理  随记   解决Anaconda pip install 出错的问题：链接
  中文分词python库：
   jieba THULAC time.clock的问题 fool LTP Hanlp   下学期开学，主要任务是学好专业课。  每天回顾今日所学，每周整理一周每门课的内容
看完每一个video，弄清楚每一个知识点，搞明白每一道题目，做好每一份记录
学有余力，
 刷leetcode 看李航《统计学习方法》、《百面机器学习》。 学李宏毅机器学习和斯坦福的nlp网课  </description>
    </item>
    
    <item>
      <title>日记</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/28/diary/</link>
      <pubDate>Tue, 28 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/28/diary/</guid>
      <description>专业课  FSI slides 整理 PfS exercise  读书 《财务自由之路》遇到贵人的方法
Leetcode 刷了三道编程题，汉诺塔问题，最长公共子串，子数组最大乘积，用时有点久。
随记 做leetcode编程题，谋定而后动！
光看一本书还不够，得多去看看不同的书。
例子很重要！</description>
    </item>
    
    <item>
      <title>条件随机场</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/28/em-gmm/</link>
      <pubDate>Tue, 28 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/28/em-gmm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>日记</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/27/diary/</link>
      <pubDate>Mon, 27 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/27/diary/</guid>
      <description>专业课 看了FSI最后一节课的video，其中的很多内容还需要复习整理
读书  《金字塔原理》如何构建金字塔 《财务自由之路》人生最重的枷锁是“安全感”，生活的根基“活在未来”  Leetcode 刷了两道编程题，最长回文子串、矩阵的最小路径和
生活 买菜
买菜、洗菜、做饭、吃饭、洗碗、消毒，这些日常生活琐事，真的是很占用时间，今天下午4点出去买了个菜，回来洗个澡，做饭，吃饭，洗碗，一套流程下来，已经快晚上8点了，4个小时就这么没了！真的很难让人接受这个事实。目前放假在公寓，一周至少要出去买两次菜，一天至少要花2个小时的时间在吃饭上。不过想想这似乎也是必须的。在这个疫情特别严重的特殊时期，消毒，不吃外卖，自己做饭，是最安全的。自己还是努力想办法提高自己的效率吧！</description>
    </item>
    
    <item>
      <title>牛客网刷题记录</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/27/leetcode/</link>
      <pubDate>Mon, 27 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/27/leetcode/</guid>
      <description>动态规划 要点：
 如何定义$dp[i][j]$ 状态转移方程是什么？  NC17 最长回文子串 对于长度为n的一个字符串A（仅包含数字，大小写英文字母），请设计一个高效算法，计算其中最长回文子串的长度。
 动态规划 $$P(i,j)=\begin{cases}1, &amp;amp; \text{if s[i]-s[j]是回文串} \\ 0&amp;amp; \text{else}\end{cases}$$ $$P(i,j)=P(i+1,j-1)\wedge(s_i==s_j)$$ 中心扩展法（回文相关trick）  NC59 矩阵的最小路径和 描述：给定一个 n * m 的矩阵 a，从左上角开始每次只能向右或者向下走，最后到达右下角的位置，路径上所有的数字累加起来就是路径和，输出所有的路径中最小的路径和。 要点：
 构建dp矩阵，空间复杂度O(nm)，时间复杂度O(nm)。  dp[i][j] = min(dp[i-1][j],dp[i][j-1]) + matrix[i][j] 可先初始化第一行，第一列
要使得空间复杂度为O(1)，只需原地修改。  NC67 汉诺塔问题 整体与部分
描述：我们有由底至上为从大到小放置的 n 个圆盘，和三个柱子（分别为左/中/右即left/mid/right），开始时所有圆盘都放在左边的柱子上，按照汉诺塔游戏的要求我们要把所有的圆盘都移到右边的柱子上，要求一次只能移动一个圆盘，而且大的圆盘不可以放到小的上面。
请实现一个函数打印最优移动轨迹。
 将左柱上面的n-1个移到中柱 左柱剩下的一个移到右柱 中柱上的n-1个移到右柱  NC83 子数组最大乘积 给定一个double类型的数组arr，其中的元素可正可负可0，返回连续子数组累乘的最大乘积。
dpp[i] = max(arr[i],arr[i]*dpp[i-1],arr[i]*dpn[i-1]) dpn[i] = min(arr[i],arr[i]*dpp[i-1],arr[i]*dpn[i-1]) NC127 最长公共子串 描述：给定两个字符串str1和str2,输出两个字符串的最长公共子串
题目保证str1和str2的最长公共子串存在且唯一。
 $dp[i][j]$:字符串str1中第i个字符和str2中第j个字符为最后一个元素所构成的最长公共子串的长度 转移方程  $$dp[i][j]=\begin{cases}0, &amp;amp; \text{if s[i]}\neq{s[j]} \\ dp[i-1][j-1] + 1&amp;amp; \text{else}\end{cases}$$</description>
    </item>
    
    <item>
      <title>EM算法</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/26/em-gmm/</link>
      <pubDate>Sun, 26 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/26/em-gmm/</guid>
      <description>EM 目的： 对含有隐变量的模型进行极大似然估计
算法： 主要有两步：
 E步：求期望; $$Q\left(\theta, \theta^{(i)}\right)=E_{Z}\left[\log P(Y, Z \mid \theta) \mid Y, \theta^{(i)}\right]$$ M步，求极大 $$\theta^{(i+1)}=\arg \max _{\theta} Q\left(\theta, \theta^{(i)}\right)$$  Tips 受初始值影响
Gaussian Mixture Model (GMM) 定义： $$P(y \mid \theta)=\sum_{k=1}^{K} \alpha_{k} \phi\left(y \mid \theta_{k}\right)$$
Tips GMM是EM算法的一个应用，可以用来解决聚类问题。</description>
    </item>
    
    <item>
      <title>日记</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/26/diary/</link>
      <pubDate>Sun, 26 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/26/diary/</guid>
      <description>专业课 过完了FSI problem set6
机器学习  EM算法 高斯混合模型 隐马尔科夫模型  读书  《金字塔原理》金字塔内部的结构 《财务自由之路》我们最重要的财富是注意力、付费就是捡便宜  其他 制定了下一周的计划</description>
    </item>
    
    <item>
      <title>Statistical inference 7</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/25/statistical-inference-7/</link>
      <pubDate>Sat, 25 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/25/statistical-inference-7/</guid>
      <description>Reference: Fundamentals of Statistical Inference&amp;mdash;&amp;mdash;G.Alastair Young
 Likelihood Theory Maximum likelihood estimator After observing $x$, the likelihood function is defined by
$$L(\theta) \equiv L(\theta ; x)=f(x ; \theta)$$
viewed as a function of $\theta$ for the fixed $x$.
The maximum likelihood estimate (MLE) $\hat{\theta}(x)$ is defined to be the value of $\theta$ which maximizes $L(\theta)$.
Log-likelihood Usually we work with the log-likelihood $$I(\theta) \equiv I(\theta ; x)=\log L(\theta)$$
Score function and information We define the score function by</description>
    </item>
    
    <item>
      <title>日记</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/25/diary/</link>
      <pubDate>Sat, 25 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/25/diary/</guid>
      <description>专业课  FSI 第七章整理完 FSI Problem set 5 过完  读书  《财务自由之路》三章 《金字塔原理》第一篇一章  机器学习  隐马尔科夫模型看了一节半  随记： 学习一个新的、重要的概念，至少要学习三遍。第一遍重在了解全貌，第二遍重在弄清所有细节，第三遍重在梳理逻辑关系。 在学习的过程中，要勤于记录，减少因遗忘而再度温习所需的时间成本。
一有空余的时间，就去看书，减少刷手机、看直播的时间。
Attention is all you need! 注意自己的注意力</description>
    </item>
    
    <item>
      <title>财务自由之路摘录</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/25/book-1/</link>
      <pubDate>Sat, 25 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/25/book-1/</guid>
      <description>理解真正的“财富自由” 能真正影响行动的关键，我们要的自由，最根本不是财富，财富只是工具，我们要的自由，本质是时间的自主权。
个人财富自由，指的是某个人再也不用为了满足生活必需而出售自己的时间了。
专注成长而不是专注成功
财富自由不是终点，那只是通往终点过程中的一个里程碑而已。
清晰且正确的概念是一切思考的基石。而衡量一个人是否聪明，几乎可以凝炼这两个条件：有没有足够多清晰、准确、正确的概念；概念之间有没有清晰、准确、正确的联系。
“嫩”的一种表现：只知道自己不想要什么，却并不知道自己想要什么。
我见过这种人，知道其实完全沒有谁可以帮上他们,他们自找的——任凭产生厌恶情绪的错误念头占领自己的大脑。
出售时间的三条铁律 出售时间的三条铁律：成长才是根本关键，重视价值忽略估值，耐心比什么都重要。
成长才是永恒的刚需。
不要让自己的估值过分超过自己的实际价值。
在你不得不用自己的时间为生活必需做交換的阶段，千万不要把一份工作随便想成一份工作，而是真的是在卖命。
我们生命中发生的事情，都不应作为终点，而是里程碑。
选择的判断标准有一个就足够了：我选择的事能不能让我积累更多的能力？
还有一种和走向财富自由里程碑矛盾的，而且迷惑性更大的是，就是所谓稳定（可能还颇高薪）的工作。细想一下，稳定如同一张温床，不需要突破，也就不需要成长、不需要进一步学习。做这样的工作可能会有一些聊以自慰的成就感（多半来自稳定)，但是因为没有成长，而一辈子不可能跨越里程碑。
真正正确的思考方式应该是：在这个选择之后，能帮我完善哪个已有能力，能让我获得什么新能力。
因为当你在意估值的时候，你就会忘记你的价值，你就会不由自主做那些提高你估值的事，而不是去想办法提高你的价值。
没耐心的人不会有好的积累，他们不会把每件事都当作自己的事来做；没耐心的人当然也更注重估值，甚至愿意为之而自欺和欺人，因为他们只能想到短期效益；没耐心的人甚至都不会思考真正重要的事价值。
大多数的人仅仅是知道而已，只有极少数人执拗地、彻底地、不折不扣地执行了这些原则……
阻碍财富自由的三大坑 三个大坑：莫名其妙地凑热闹，心急火燎地随大流，操碎了别人的心肝。
你必须把最宝贵的注意力全部放在你自己身上的“成长”。
创业就是成长。没有成长就不是创业。
不珍惜自己注意力的人，最终注定是贫穷的，因为他们终生被收割，终生不可能有真正有价值的产出，怎么可能最终变得富有？
那么多的人其实没什么正事儿可做，连读书都不会，闲得要死；大量闲置的时间杀掉，大量闲置的精力需要被发泄，大量的好奇心需要个喷射的出口……
在任何一个大的趋势出现的时候，一定有另外一批人，早就准备好了——虽然可能并不是有意准备的。
可惜，平日里只有一颗上进的心，一样滚烫，却从未有过积累的行动。
什么是每个人都拥有的、最重要、却被人忽视了的宝贵财富？注意力。
你的注意力，真的很少，一天下来，能够集中起来有产出的注意力，弄不好往往只有两三个小时而已，结果呢？结果你去凑热闹，你去随大流，你去操别人的心. . . 若是这样，不消说你能不能成功，仅仅&amp;quot;有收获&amp;quot;都是根本做不到的，不是吗？
你必须把最宝贵的注意力全部放在你自己身上。
这世上有个很简单却又长期成功的商业模式：把海量的廉价甚至免费的注意力集中起来高价卖掉。
你若是胆敢不在意你的注意力，你的注意力(事实上你的注意力其实就是真正有价值的你）就会被无情地收割起来然后被卖掉。
我们最重要的财富是注意力 当有些人问到为什么自己的行程满满当当，却依然感觉无甚收获时，我就会提醒他们，满的，是你的时间；闲置的，是你的注意力；荒废的，是你的成长。
要把注意力放在自己的成长上。放在一切可以有积累效应的技能上，然后给予充分的学习、思考和磨炼。
要把注意力不求回报地放到真爱身上，这是真正幸福的关键。
把注意力放在对整个社会真正有贡献的事情上去。个体价值等于他的社会贡献率。
你必须把最宝贵的注意力全部放在你自己身上。
任何由于信息不对称造成的泡沬都会以越来越快的速度瓦解
付费就是捡便宜 凡是能用钱买的其实都是便宜的。
手机永远设置为静音，所有的push notification全都关掉。
凡是能用钱买来的时间就是便宜的；凡是能用时间换来的注意力持续就是有价值的。
把注意力放到能够提升自己的事情上，让这件事逼你拿出注意力，拿出时间，进而逼你拿钱去换时间和注意力。
在经济能力承受范围内，选最贵的。
你所拥有的最宝贵的财富是你的注意力。
很多人留言说，不知道该用注意力去干嘛。
 积累知识 磨炼技能 观察生活 思考未来 创造价值 经营人脉  人在心情不好的时候，注意力是无法集中的，什么事儿都干不成，什么事儿都做不好，什么番茄时间管理法之类的东西再怎么有道理，其实都根本就没有“用武之地”，不是吗？
把足够多的时间花在她身上。如果可能的话，也花足够多的钱在她身上。
我专注做事的时候，就是不该接受任何打扰的。等我停下来，休息的时候，可以顺手处理那些未读短信和未接来电。
我用我的大量时间与她进行有效沟通，最终使得我不被无谓地干扰，让我的注意力有更多持续的机会，有更多产出的能量。这就是我的方法，花时间换取注意力持续。
许多家庭不幸福的根本原因就是相互之间时间与注意力投资太少——就这么简单。
想要别人主动接近你，最好的方法就是时不时做出令人敬佩的事情。
人生最重的枷锁是“安全感” 几乎所有的进步都是放弃了部分安全感才可能获得的。
追求百分之百的安全感，肯定会把自己困在永恒的当下。
我们必须放弃一部分安全感，才能深入长期地观察、思考。</description>
    </item>
    
    <item>
      <title>金字塔原理摘录</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/25/book-2/</link>
      <pubDate>Sat, 25 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/25/book-2/</guid>
      <description>表达的逻辑 对受众（包括读者、听众、观众或学员）来说，最容易理解的顺序是：先了解主要的、抽象的思想，然后了解次要的、为主要思想提供支持的思想。
为什么要采用金字塔结构 归类分组，构建金字塔式思维结构
只有金字塔结构才能满足大脑的两个需求：
 一次记忆不超过7个思想、概念或项目。 找出逻辑关系。  大脑的短期记忆无法一次容纳7个以上的记忆项目。有的人可能一次能记住9个项目，而有的人只能记住5个。大脑比较容易记住的是3个项目，当然最容易记住的是1个项目。
找出逻辑关系，抽象概括
最有效的方法是：先提出总的概念，再列出具体项目，即自上而下地呈现思想。
自上而下，结论先行
清晰的顺序就是先提出总结性思想，再提出被总结的具体思想。先总结后具体的表达顺序，请一定要牢记。
自下而上思考，总结概括
因为演绎推理、发现因果关系、化整为零和归纳总结是大脑可以进行的仅有的4种分析活动，这4种顺序也是大脑可用于组织思想的仅有的4种顺序。
要写出条理清晰的文章，关键就是在开始写作之前，先将你的思想放入金字塔结构中，并根据以上规则进行检验。
组织思想基本上只有4种逻辑顺序：
 演绎顺序：大前提、小前提、结论； 时间（步骤）顺序：第一、第二、第三； 结构（空间）顺序：波士顿、纽约、华盛顿； 程度（重要性）顺序：最重要、次重要，等等。  金字塔内部的结构 不要幻想一坐下来就能将思想组织成金字塔。首先你必须梳理想要表达的思想。
金字塔中的子结构，能够加快你梳理思想的过程：
 主题与子主题之间的纵向关系。 各子主题之间的横向关系。 序言的叙述方式。  纵向关系
你的回答仍然是向读者传递他不知道的新信息，这又会使读者产生新的疑问，于是你又需要在再下一个层次回答读者新的疑问。
你的每一个表述都应当引发读者的疑问，而你也必须在这一表述之下的层次上，在横向上逐个回答读者的疑问。
横向关系
当考虑在下一结构层次上如何表述时，必须保证你的表述能回答上一个层次的表述引起的疑问，还必须保证符合逻辑。也就是说，表述必须具有明确的归纳或演绎关系，但不可既具有归纳关系，又具有演绎关系。在组织思想时，归纳和演绎是仅有的两种可能的逻辑关系。
序言的结构
保证产生相关性的唯一办法，就是确保对话直接回答了你所发现的业已存在于读者头脑中的疑问。
虽然写作的主要目的是告诉别人他们不知道的信息，但是，读者只有在需要了解这些他所不知道的信息时才会去寻找答案。如果读者没有这种需要，就不会提出任何疑问，也谈不上找答案，反之亦然。
如何构建金字塔 自上而下法
但是，你不能现在就坐下来开始写序言。应当先利用序言的结构，将头脑中的观点、论点、想法逐个梳理出来。
采用自上而下法构建金字塔的步骤：
 提出主题思想。 设想受众的主要疑问。 写序言：背景—冲突—疑问—回答。 与受众进行疑问－回答式对话。 对受众的新疑问，重复进行疑问－回答式对话。  自下而上法
自下而上思考：
 列出你想表达的所有思想要点。 找出各要点之间的逻辑关系。 得出结论。  初学者注意事项
 要先尝试自上而下法。 序言先写背景，将背景作为序言的起点。 多花点时间思考序言，不要省略这一步。 将背景放在序言中。 序言仅涉及读者不会对其真实性提出质疑的内容。 在关键句层次上，更宜选择归纳法而非演绎法。  </description>
    </item>
    
    <item>
      <title>隐马尔科夫模型</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/25/hmm/</link>
      <pubDate>Sat, 25 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/25/hmm/</guid>
      <description> refer to 《统计学习方法》——李航
 隐马尔科夫模型的基本概念 定义 隐马尔科夫模型由初始概率分布、状态转移概率分布、观测概率分布确定。（三要素）
两个基本假设：
 齐次马尔科夫性假设 观测独立性假设  观测序列的生成过程 隐马尔科夫模型的三个基本问题  概率计算问题 学习问题 预测问题  概率计算算法 直接计算法 前向算法 后向算法 学习算法 监督学习方法 Baum-Welch算法（EM算法） 预测算法 近似算法 维特比算法（动态规划） </description>
    </item>
    
    <item>
      <title>帮高哥申PhD！</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/24/apply-phd/</link>
      <pubDate>Fri, 24 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/24/apply-phd/</guid>
      <description>上上策 去国外读PhD，进谷歌、亚马逊
论文： 发一两篇论文
语言：  目标：托福100 首做：阅读24，听力20 研二暑假考  推荐人  闫亮 实习老板 李铁香、王海兵  信息搜集  知乎 一亩三分地  时间线  2021-12-24讨论  找学长学姐、老师、老板，交流有申国外phd的想法，听听他们的意见</description>
    </item>
    
    <item>
      <title>日记</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/24/diary/</link>
      <pubDate>Fri, 24 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/24/diary/</guid>
      <description>专业课  过完FSI Problem set 4 PS 16-17和17-18的往年卷过完  读书  数学之美读了两章  需要改进的地方  专注 提高效率  插曲 突然停电了
随记 今天看了youtube上meta公司关于元宇宙的视频，个人不是很看好元宇宙，感觉可能是个骗局。扎克伯格像是在画一个大饼，更多的可能是在炒概念，而没有推出实质性的产品。不过还是不得不感叹技术发展日新月异。作为一个现代人，在高速发展的时代，很容易迷失自我，更需要经常问问自己，什么是自己真正想要的？作为一个求职者，是追随时代新潮流，不断寻找风口；还是静心沉淀，努力耕耘好自己的一亩三分地？作为一个产品经理，什么是一个好的产品？产品的价值体现在何处？作为一个企业家，需要打造一个什么样的企业？企业的价值观是什么？</description>
    </item>
    
    <item>
      <title>Statistical inference 6</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/23/statistical-inference-6/</link>
      <pubDate>Thu, 23 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/23/statistical-inference-6/</guid>
      <description>Reference: Fundamentals of Statistical Inference&amp;mdash;&amp;mdash;G.Alastair Young
 Key Element of Frequentist Theory Fundamental characteristic Explicit optimality criteria.
 Hypothesis testing: seek test which maximizes power. Point estimation: seek estimator which minimizes risk.  Classical approach Adopt the following criterion: fix a small probability $\alpha$ (known as the size) and seek a test for which
$$\mathbb{P}_{\theta}\left\{\text { Reject } H_{0}\right\} \leq \alpha \quad \text { for all } \theta \in \Theta_{0}$$</description>
    </item>
    
    <item>
      <title>日记</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/23/diary/</link>
      <pubDate>Thu, 23 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/23/diary/</guid>
      <description>专业课  完成FSI第六的笔记整理  生活  拖地 清洗浴室下水道  需要改进的地方 专注于做事情！</description>
    </item>
    
    <item>
      <title>Statistical inference 4</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/22/statistical-inference-4/</link>
      <pubDate>Wed, 22 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/22/statistical-inference-4/</guid>
      <description>Reference: Fundamentals of Statistical Inference&amp;mdash;&amp;mdash;G.Alastair Young
 Special Families of Models Exponential Families Suppose that $Y$ depends on parameter $\phi = (\phi^1,\cdots,\phi^m)^T$, to be called natural parameters, through a density of the form
$$f_{Y}(y ; \phi)=h(y) \exp \left\{s^{T} \phi-K(\phi)\right\}, \quad y \in \mathcal{Y}$$
where $\mathcal{Y}$ is a set not depending on $\phi$. Here $s \equiv s(y)=\left(s_{1}(y), \ldots, s_{m}(y)\right)^{T}$, are called natural statistics.
$$E\left(S_{i} ; \phi\right)=\frac{\partial K(\phi)}{\partial \phi^{i}}$$
$$\operatorname{cov}\left(S_{i}, S_{j} ; \phi\right)=\frac{\partial^{2} K(\phi)}{\partial \phi^{i} \partial \phi^{j}}$$</description>
    </item>
    
    <item>
      <title>Statistical inference 5</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/22/statistical-inference-5/</link>
      <pubDate>Wed, 22 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/22/statistical-inference-5/</guid>
      <description>Reference: Fundamentals of Statistical Inference&amp;mdash;&amp;mdash;G.Alastair Young
 Principles of Inference and Data Reduction Likelihood Likelihood function: $$L(\theta;y) = f_Y(y;\theta)$$ Log-likelihood: $$I(\theta;y) = \log f_Y(y;\theta)$$
Likelihood Principle The (strong) likelihood principle is that if $y$ and $z$ give proportional likelihood functions, the conclusions drawn from y and z should be identical, assuming adequacy of both models.
If, for all $\theta\in\Omega_\theta$, $$f_Y(y;\theta) = h(y,z)f_Z(z;\theta)$$ identical conclusions about $\theta$ should be drawn from $y$ and $z$.</description>
    </item>
    
    <item>
      <title>日记</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/22/diary/</link>
      <pubDate>Wed, 22 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/22/diary/</guid>
      <description>专业课  完成FSI第四章、第五章的笔记整理 过完FSI的Problem set 3  机器学习  logistic regression 实现  读书  数学之美读了两章  生活  理发  需要改进的地方  看PfS！  </description>
    </item>
    
    <item>
      <title>Statistical inference 3</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/21/statistical-inference-3/</link>
      <pubDate>Tue, 21 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/21/statistical-inference-3/</guid>
      <description>Reference: Fundamentals of Statistical Inference&amp;mdash;&amp;mdash;G.Alastair Young
 Bayesian Methods Posterior density The posterior density of $\theta$, conditional on the observed value $Y=y$, is derived by applying Bayes&#39; rule:
$$\pi(\theta \mid y)=\frac{\pi(\theta) f(y ; \theta)}{\int_{\Omega_{\theta}} \pi\left(\theta^{\prime}\right) f\left(y ; \theta^{\prime}\right) d \theta^{\prime}}$$
$$\pi(\theta|y)\propto\pi(\theta)f(y;\theta)$$
$$\text{posterior}\propto\text{prior}\times\text{likelihood}$$
The general form of Bayes rule To minimize the Bayes risk $r(\pi,d))$ is equivalent to minimize $$\int_{\Omega_{\theta}} L(\theta, d(y)) \pi(\theta \mid y) d \theta$$
James-Stein estimator Let $Y$ have a $p$-dimensional ($p \geq 3$) normal distribution with mean vector µ and known covariance matrix equal to the identity $I$, so that $Y_i\sim N(\mu_i,1)$, independently, $i=1,\cdots,p$.</description>
    </item>
    
    <item>
      <title>如何洗碗又快又干净</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/21/wash-dish/</link>
      <pubDate>Tue, 21 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/21/wash-dish/</guid>
      <description> refer to Zhi hu
 步骤  吃完马上洗 or 拿水先泡着（确保浸没） 温水 洗碗布弄湿，洗洁精倒在洗碗布上 里外擦一遍，放到一边 洗下一个碗，摞在前一个碗上，洗碗布不用沾水 对所有碗进行重复操作，然后同理用洗碗布擦洗锅、铲、刀之类的厨具、餐桌和料理台。 擦洗完毕后，在水龙头下冲洗碗布 将初步洗净的碗、厨具，依次放在流动的水龙头下冲洗，用手抚一遍 用冲洗干净的洗碗布松松拧一下，擦餐桌和料理台。 洗碗布拧干，再擦一遍餐桌和料理台。 洗干净洗碗布，晾干。  有条件了买洗碗机（亚马逊上£250左右）
目标： 洗两人份吃的锅碗，用时不超过10分钟
记录  2021-12-21 10&#39;57  </description>
    </item>
    
    <item>
      <title>日记</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/21/diary/</link>
      <pubDate>Tue, 21 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/21/diary/</guid>
      <description>专业课  完成FSI第三章的笔记整理 过完FSI的Problem set 1,2 看完PS最后一节课的video  读书  数学之美看了两章  需要改进的地方  早起！ PS 要开始做题了！  疑问  个人博客 post 文件夹下面的显示格式有问题  </description>
    </item>
    
    <item>
      <title>桂圆烧蛋</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/21/longan-egg/</link>
      <pubDate>Tue, 21 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/21/longan-egg/</guid>
      <description> refer to 下厨房
 用料：鸡蛋、桂圆肉、冰糖、枸杞
做法：
 用水冲洗桂圆肉 烧一锅水，放桂圆肉、冰糖 烧开后，小火炖15分钟 打一个鸡蛋进去，中火滚一会儿，小火焖一会儿 放入枸杞，出锅  Tips:
 冰糖最好用红糖代替 可以放红枣  </description>
    </item>
    
    <item>
      <title>Chrome 常用快捷键总结</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/20/chrome-shortcut/</link>
      <pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/20/chrome-shortcut/</guid>
      <description> Reference to Chrome keyboard shortcuts
 Common chrome shortcuts    action shortcut     Open a new window Ctrl + n   Open a new window in Incognito mode Ctrl + Shift + n   Open a new tab, and jump to it Ctrl + t   Reopen previously closed tabs in the order that they were closed Ctrl + Shift + t   Jump to the next open tab Ctrl + Tab or Ctrl + PgDn   Jump to the previous open tab Ctrl + Shift + Tab or Ctrl + PgUp   Jump to a specific tab Ctrl + 1 through Ctrl + 8   Jump to the rightmost tab Ctrl + 9   Open your home page in the current tab Alt + Home   Open the previous page from your browsing history in the current tab Alt + Left arrow   Open the next page from your browsing history in the current tab Alt + Right arrow   Close the current tab Ctrl + w or Ctrl + F4   Close the current window Ctrl + Shift + w or Alt + F4   Minimize the current window Alt + Space then n   Maximize the current window Alt + Space then x   Quit Google Chrome Alt + f then x   Open the Chrome Task Manager Shift + Esc   Open the Bookmarks Manager Ctrl + Shift + o   Search from anywhere on the page Ctrl + k or Ctrl + e   Jump to the next match to your Find Bar search Ctrl + g   Jump to the previous match to your Find Bar search Ctrl + Shift + g   Open options to print the current page Ctrl + p   Reload the current page F5 or Ctrl + r   Save your current web page as a bookmark Ctrl + d   Save all open tabs as bookmarks in a new folder Ctrl + Shift + d   Turn full-screen mode on or off F11   Make everything on the page bigger Ctrl and +   Make everything on the page smaller Ctrl and -   Return everything on the page to default size Ctrl + 0   Go to the top of the page Home   Go to the bottom of the page End   Open the Home page in the current tab Alt + Home   Open a link in new background tab Ctrl + Click a link   Open a link, and jump to it Ctrl + Shift + Click a link   Open a link in a new window Shift + Click a link    </description>
    </item>
    
    <item>
      <title>Statistical inference 1</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/20/statistical-inference-1/</link>
      <pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/20/statistical-inference-1/</guid>
      <description>Reference: Fundamentals of Statistical Inference&amp;mdash;&amp;mdash;G.Alastair Young
 Approaches to Statistical Inference What is statistical inference? Observational data modelled as observed values of random variables, to provide framework from which inductive conclusions may be drawn about mechanism giving rise to data.
Types of inference  Point estimation Confidence set estimation Hypothesis testing  Three paradigms of inference  Bayesian Fisherian frequentist  Bayesian inference Unknown parameter $\theta$ treated as random variable.</description>
    </item>
    
    <item>
      <title>Statistical inference 2</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/20/statistical-inference-2/</link>
      <pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/20/statistical-inference-2/</guid>
      <description>Reference: Fundamentals of Statistical Inference&amp;mdash;&amp;mdash;G.Alastair Young
 Decision Theory Formulation Elements of a formal decision problem:
 Parameter space. $\Omega_\theta$ Sample space $\mathcal{Y}$. $y = (y_1,\cdots,y_n)\in\mathbb{R}^n$ Family of distributions. $\{\mathbb{P}_\theta(y),y\in\mathcal{Y},\theta\in\Omega_\theta\}$ Action space $\mathcal{A}$. Loss function $L$. Function $L:\Omega_\theta\times\mathcal{A}\rightarrow\mathbb{R}$. Decision rule $d$. Function $d:\mathcal{Y}\rightarrow\mathcal{A}$.  Risk Function $$R(\theta, d)=\mathbb{E}_{\theta} L(\theta, d(Y))=\int_{\mathcal{Y}} L(\theta, d(y)) f(y ; \theta) d y$$
Common loss function Squared error loss function: $$L(\theta,a) = (\theta-a)^2$$ Absolute error loss function: $$L(\theta,a) = |\theta-a|$$</description>
    </item>
    
    <item>
      <title>Windows10 常用快捷键总结</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/20/win10-shortcut/</link>
      <pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/20/win10-shortcut/</guid>
      <description>Reference to Windows Central
 Common Windows10 shortcuts    Keyboard shortcut Action     Ctrl + A Select all content.   Ctrl + C (or Ctrl + Insert) Copy selected items to clipboard.   Ctrl + X Cut selected items to clipboard.   Ctrl + V (or Shift + Insert)	Paste content from clipboard.   Ctrl + Z Undo an action, including undelete files (limited).</description>
    </item>
    
    <item>
      <title>日记</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/20/diary/</link>
      <pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/20/diary/</guid>
      <description>专业课  完成FSI第一章和第二章的笔记整理  整理总结  Chrome 快捷键的整理 Windows 快捷键的整理 有相似之处！ Chrome的书签是个好东西，可以整理很多网页！  something useful  vs code 里面的 Code Spell Checker Extension 可以检查拼写！ mathjax数学公式用法  </description>
    </item>
    
    <item>
      <title>建站历程</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/19/home-page/</link>
      <pubDate>Sun, 19 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/19/home-page/</guid>
      <description>这里将记录我的建站历程
本个人主页采用hugo，关于Hugo的简单教程在这里，模板参考谢益辉使用的hugo-ivy，网站建立的教程参考该youtube视频。谢益辉写的blogdown和hugo-ivy的一些说明在这里。
日后如需更新文档，输入以下git代码：
&amp;gt;hugo &amp;gt;cd public &amp;gt;git remote -v &amp;gt;git status &amp;gt;git add . &amp;gt;git commit -m &amp;#34;add something&amp;#34; &amp;gt;git push origin main 输入公式:
`$ $`
插入图片：
将图片放入 static/img 中</description>
    </item>
    
    <item>
      <title>慢炖锅做茶叶蛋</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/19/tea-eggs/</link>
      <pubDate>Sun, 19 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/19/tea-eggs/</guid>
      <description> refer to 下厨房
 用料：鸡蛋、茶叶、八角、桂皮、生抽、老抽、盐、糖
用具：慢炖锅
做法：
 将生鸡蛋煮熟 放入冰水浸泡20分钟，然后轻轻敲碎外壳 另起一锅，加水，放茶叶、八角、桂皮，倒生抽，老抽，放盐，放糖 煮10分钟，有香味后，放敲碎的鸡蛋，中火煮半小时 全部倒入慢炖锅，低档开一晚上  Tips:
 茶叶最好用红茶 鸡蛋敲碎一点，否则不入味  </description>
    </item>
    
    <item>
      <title>关于学习</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/01/02/learn/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/01/02/learn/</guid>
      <description>学习：不会到会的过程</description>
    </item>
    
  </channel>
</rss>
