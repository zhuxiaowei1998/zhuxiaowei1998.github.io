<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine learning on Xiaowei</title>
    <link>https://zhuxiaowei1998.github.io/categories/machine-learning/</link>
    <description>Recent content in machine learning on Xiaowei</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 26 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://zhuxiaowei1998.github.io/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>EM算法</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/26/em-gmm/</link>
      <pubDate>Sun, 26 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/26/em-gmm/</guid>
      <description>EM 目的： 对含有隐变量的模型进行极大似然估计
算法： 主要有两步：
 E步：求期望; $$Q\left(\theta, \theta^{(i)}\right)=E_{Z}\left[\log P(Y, Z \mid \theta) \mid Y, \theta^{(i)}\right]$$ M步，求极大 $$\theta^{(i+1)}=\arg \max _{\theta} Q\left(\theta, \theta^{(i)}\right)$$  Tips 受初始值影响
Gaussian Mixture Model (GMM) 定义： $$P(y \mid \theta)=\sum_{k=1}^{K} \alpha_{k} \phi\left(y \mid \theta_{k}\right)$$
Tips GMM是EM算法的一个应用，可以用来解决聚类问题。</description>
    </item>
    
    <item>
      <title>隐马尔科夫模型</title>
      <link>https://zhuxiaowei1998.github.io/note/2021/12/25/hmm/</link>
      <pubDate>Sat, 25 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zhuxiaowei1998.github.io/note/2021/12/25/hmm/</guid>
      <description> refer to 《统计学习方法》——李航
 隐马尔科夫模型的基本概念 定义 隐马尔科夫模型由初始概率分布、状态转移概率分布、观测概率分布确定。（三要素）
两个基本假设：
 齐次马尔科夫性假设 观测独立性假设  观测序列的生成过程 隐马尔科夫模型的三个基本问题  概率计算问题 学习问题 预测问题  概率计算算法 直接计算法 前向算法 后向算法 学习算法 监督学习方法 Baum-Welch算法（EM算法） 预测算法 近似算法 维特比算法（动态规划） </description>
    </item>
    
  </channel>
</rss>
